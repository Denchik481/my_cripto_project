services:
  # 1. S3‐совместимое хранилище MinIO
  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Web UI
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"

  # 2. Hive Metastore (для Iceberg Catalog)
  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    ports:
      - "9083:9083"
    environment:
      ALLOW_EMPTY_PASSWORD: "yes"
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_DATABASE_HOST: ""
    command: ["hive", "--service", "metastore"]
    # метаданные хранятся в встроенной HSQLDB

# 3. Spark Master
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile
    image: my-spark-custom:latest
    ports:
      - "7077:7077"   # Spark Master port
      - "8080:8080"   # Web UI
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_EXTRA_CLASSPATH=/opt/spark/extra-jars/*
    volumes:
      - ./spark/jars:/opt/spark/extra-jars
      - ./spark/conf:/opt/spark/conf
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      --host spark-master
      --port 7077
      --webui-port 8080
    depends_on:
      - minio
      - hive-metastore

  # 4. Spark Worker
  spark-worker:
    image: my-spark-custom:latest
    depends_on:
      - spark-master
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - SPARK_EXTRA_CLASSPATH=/opt/spark/extra-jars/*
    volumes:
      - ./spark/jars:/opt/spark/extra-jars
      - ./spark/conf:/opt/spark/conf
    command:
      - /opt/spark/bin/spark-class
      - org.apache.spark.deploy.worker.Worker
      - spark://spark-master:7077

  jupyter:
    build:
      context: ..               # корень проекта (где лежит pyproject.toml)
      dockerfile: docker/jupyter/Dockerfile
    image: my-crypto-jupyter:latest
    ports:
      - "8888:8888"
    volumes:
      - ../:/home/jovyan/work
    environment:
      JUPYTER_TOKEN: mytoken
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MLFLOW_TRACKING_URI: http://mlflow:5000
    command: start-notebook.sh --NotebookApp.token='mytoken'
    depends_on:
      - mlflow
      - minio

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --host 0.0.0.0
      --backend-store-uri sqlite:////mlflow/mlruns/mlflow.db
      --default-artifact-root s3://mlflow/
    environment:
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MLFLOW_ARTIFACT_ROOT: s3://mlflow/
      MLFLOW_TRACKING_URI: sqlite:///mlflow.db
    volumes:
      - ./mlruns:/mlflow/mlruns
    depends_on:
      - minio

volumes:
  minio_data: